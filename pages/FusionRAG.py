import streamlit as st

from langchain.retrievers.ensemble import EnsembleRetriever
from langchain.retrievers import BM25Retriever
from Indexing import get_vectorstore
from llm.LLM import LLM

index = get_vectorstore("VN-History")

llm = LLM()

vt_retriever = index.as_retriever()
bm_retriever = BM25Retriever.from_documents([doc for doc in index.docstore._dict.values()])
bm_retriever.k = 3

hybrid_retriever = EnsembleRetriever(
    retrievers=[vt_retriever, bm_retriever],
    weights=[0.6, 0.4]
)

st.title("Fusion RAG")


if prompt := st.text_input("Query from 'LichsuDang.pdf'"):

    st.divider()
    from llm.Chain import query_expansion_chain
    with st.spinner("ƒêang t·∫°o c√°c truy v·∫•n m·ªü r·ªông..."):
        expanded_queries_raw = query_expansion_chain.invoke({"question": prompt})
        expanded_queries = [q.strip() for q in expanded_queries_raw.split('\n') if q.strip()]
        if prompt not in expanded_queries:
            expanded_queries.insert(0, prompt)
        st.subheader("C√°c truy v·∫•n ƒë√£ ƒë∆∞·ª£c m·ªü r·ªông:")
        for i, q in enumerate(expanded_queries):
            st.write(f"- `{q}`")

    st.divider()


    all_retrieved_docs_map = []
    with st.expander("Xem k·∫øt qu·∫£ truy xu·∫•t cho t·ª´ng truy v·∫•n"):
        for i, query_to_search in enumerate(expanded_queries):
            st.subheader(f"üîç `{query_to_search}`")
            
            with st.spinner(f"ƒêang th·ª±c hi·ªán Hybrid Search cho '{query_to_search}'..."):
                hybrid_docs = hybrid_retriever.get_relevant_documents(query_to_search)
                st.markdown(f"**K·∫øt qu·∫£ Hybrid Search ({len(hybrid_docs)} docs):**")
                for doc in hybrid_docs:
                    st.write(f"- `{doc.page_content[:100].replace('\n', ' ')}...`")
                    all_retrieved_docs_map.append(hybrid_docs) 
            st.divider()

    st.success(f"T·ªïng s·ªë t√†i li·ªáu ƒë∆∞·ª£c truy xu·∫•t: **{len(all_retrieved_docs_map)}**")
    st.divider()


    from llm.utils import reciprocal_rank_fusion
    with st.spinner("ƒêang h·ª£p nh·∫•t v√† x·∫øp h·∫°ng l·∫°i c√°c t√†i li·ªáu..."):
        reranked_docs = reciprocal_rank_fusion(all_retrieved_docs_map)
        st.subheader("Top 4 t√†i li·ªáu ƒë√£ ƒë∆∞·ª£c h·ª£p nh·∫•t v√† x·∫øp h·∫°ng l·∫°i b·∫±ng RRF:")
        for i, (doc, score) in enumerate(reranked_docs[:5]):
            st.write(f"**{i+1}.** {score:.4f} - `{doc.page_content[:150].replace('\n', ' ')}...`")
    st.divider()

    context_docs = reranked_docs[:4]
    context = "\n\n".join([doc.page_content for doc, _ in context_docs])
    with st.spinner("ƒê·∫°ng t·∫°o c√¢u tr·∫£ l·ªùi..."):
        response = llm.invoke(prompt, context)
        st.subheader("C√¢u tr·∫£ l·ªùi cu·ªëi c√πng:")
        st.write(response)

        
